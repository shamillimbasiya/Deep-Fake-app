{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sE22UQtQ9YYi"
   },
   "source": [
    "# **Please use @justinjohn colab notebook which is better and actually works  https://colab.research.google.com/github/justinjohn0306/Wav2Lip/blob/master/Wav2Lip_simplified_v5.ipynb**\n",
    "\n",
    "# **There is no need for colab pro to use it.**\n",
    "[Discord](https://discord.gg/F5WzXC8vXJ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT9AQwdf8sJK"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ5taGmPcWV-"
   },
   "source": [
    "# **Get the code and models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qgo-oaI3JU2u",
    "outputId": "921cc07e-35f2-4d90-eb33-4a4a89fe5554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#@title <h1>Step1: Setup Wav2Lip</h1>\n",
    "#@markdown * Install dependency\n",
    "#@markdown * Download pretrained model\n",
    "#!rm -rf /content/sample_data\n",
    "#!mkdir /content/sample_data\n",
    "\n",
    "#!git clone https://github.com/zabique/Wav2Lip\n",
    "\n",
    "#download the pretrained model\n",
    "#!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
    "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
    "\n",
    "# !pip uninstall tensorflow tensorflow-gpu\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "#download pretrained model for face detection\n",
    "#!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
    "\n",
    "!pip install -q youtube-dl\n",
    "!pip install ffmpeg-python\n",
    "!pip install librosa==0.9.1\n",
    "\n",
    "#this code for recording audio\n",
    "\"\"\"\n",
    "To write this piece of code I took inspiration/code from a lot of places.\n",
    "It was late night, so I'm not sure how much I created or just copied o.O\n",
    "Here are some of the possible references:\n",
    "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
    "https://stackoverflow.com/a/18650249\n",
    "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
    "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
    "https://stackoverflow.com/a/49019356\n",
    "\"\"\"\n",
    "from IPython.display import HTML, Audio\n",
    "#from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzokJMO19IyY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgjaWJFs8B38"
   },
   "source": [
    "# **Quick guide**\n",
    "1. Create video file named input_video.mp4 - audio track removed\n",
    "2. Create audio file named input_audio.wav\n",
    "3. Both files have to be exact same length\n",
    "4. Target face in the input_video.mp4, must be \"detectable\" in ALL videoframes (So no black or blurry frames etc)\n",
    "5. Make sure u use correct file extensions\n",
    "6. wav2lip does not like very long and high res clips (1080p/30seconds max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdIQfY2Kswcb"
   },
   "source": [
    "# **Now lets try!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bDRYsfXTzXD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jR5utmDMcSZY",
    "outputId": "1f8aef35-0425-4445-8293-a453c88f925e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference.\n",
      "Reading video frames...\n",
      "Number of frames available for inference: 308\n",
      "/home/eliho/TDDE19/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
      "(80, 705)\n",
      "Length of mel chunks: 216\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]/home/eliho/TDDE19/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_weights = torch.load(path_to_detector)\n",
      "\n",
      "  0%|                                                    | 0/14 [02:12<?, ?it/s]\u001b[A\n",
      "Recovering from OOM error; New batch size: 8\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▋                                          | 1/27 [00:07<03:16,  7.56s/it]\u001b[A\n",
      "  7%|███▎                                        | 2/27 [00:08<01:37,  3.88s/it]\u001b[A\n",
      " 11%|████▉                                       | 3/27 [00:10<01:04,  2.69s/it]\u001b[A\n",
      " 15%|██████▌                                     | 4/27 [00:11<00:49,  2.13s/it]\u001b[A\n",
      " 19%|████████▏                                   | 5/27 [00:12<00:37,  1.72s/it]\u001b[A\n",
      " 22%|█████████▊                                  | 6/27 [00:13<00:30,  1.47s/it]\u001b[A\n",
      " 26%|███████████▍                                | 7/27 [00:14<00:26,  1.31s/it]\u001b[A\n",
      " 30%|█████████████                               | 8/27 [00:15<00:22,  1.20s/it]\u001b[A\n",
      " 33%|██████████████▋                             | 9/27 [00:16<00:20,  1.13s/it]\u001b[A\n",
      " 37%|███████████████▉                           | 10/27 [00:17<00:18,  1.09s/it]\u001b[A\n",
      " 41%|█████████████████▌                         | 11/27 [00:18<00:16,  1.06s/it]\u001b[A\n",
      " 44%|███████████████████                        | 12/27 [00:19<00:15,  1.05s/it]\u001b[A\n",
      " 48%|████████████████████▋                      | 13/27 [00:20<00:14,  1.06s/it]\u001b[A\n",
      " 52%|██████████████████████▎                    | 14/27 [00:21<00:14,  1.10s/it]\u001b[A\n",
      " 56%|███████████████████████▉                   | 15/27 [00:22<00:13,  1.14s/it]\u001b[A\n",
      " 59%|█████████████████████████▍                 | 16/27 [00:24<00:12,  1.16s/it]\u001b[A\n",
      " 63%|███████████████████████████                | 17/27 [00:25<00:11,  1.17s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 18/27 [00:26<00:10,  1.14s/it]\u001b[A\n",
      " 70%|██████████████████████████████▎            | 19/27 [00:27<00:08,  1.10s/it]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 20/27 [00:28<00:07,  1.13s/it]\u001b[A\n",
      " 78%|█████████████████████████████████▍         | 21/27 [00:29<00:07,  1.17s/it]\u001b[A\n",
      " 81%|███████████████████████████████████        | 22/27 [00:31<00:06,  1.20s/it]\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 23/27 [00:32<00:04,  1.22s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████▏    | 24/27 [00:33<00:03,  1.24s/it]\u001b[A\n",
      " 93%|███████████████████████████████████████▊   | 25/27 [00:34<00:02,  1.25s/it]\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 26/27 [00:36<00:01,  1.25s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 27/27 [00:37<00:00,  1.39s/it]\u001b[A\n",
      "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
      "/home/eliho/TDDE19/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n",
      "Model loaded\n",
      "100%|█████████████████████████████████████████████| 2/2 [02:53<00:00, 86.72s/it]\n",
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
      "\u001b[0mInput #0, wav, from 'output.wav':\n",
      "  Duration: 00:00:08.80, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
      "Input #1, avi, from 'temp/result.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf59.27.100\n",
      "  Duration: 00:00:08.67, start: 0.000000, bitrate: 2986 kb/s\n",
      "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 2987 kb/s, 24.92 fps, 24.92 tbr, 24.92 tbn, 623 tbc\n",
      "Stream mapping:\n",
      "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mprofile High, level 4.0, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=34 lookahead_threads=5 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results/result_voice.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 24.92 fps, 19136 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 aac\n",
      "frame=  216 fps=0.0 q=-1.0 Lsize=    1496kB time=00:00:08.78 bitrate=1393.9kbits/s speed=9.25x    \n",
      "video:1420kB audio:69kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.440343%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mframe I:1     Avg QP:17.45  size: 45400\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mframe P:65    Avg QP:17.39  size: 15370\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mframe B:150   Avg QP:20.90  size:  2729\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mconsecutive B-frames:  6.5%  1.9%  2.8% 88.9%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mmb I  I16..4: 52.9% 46.7%  0.4%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mmb P  I16..4:  1.9%  5.8%  0.1%  P16..4: 24.1%  5.9%  2.8%  0.0%  0.0%    skip:59.4%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mmb B  I16..4:  0.2%  0.7%  0.0%  B16..8: 21.0%  0.7%  0.0%  direct: 0.4%  skip:77.0%  L0:49.0% L1:49.1% BI: 1.8%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0m8x8 transform intra:70.5% inter:83.8%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mcoded y,uvDC,uvAC intra: 32.5% 50.4% 9.9% inter: 3.2% 5.4% 0.2%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mi16 v,h,dc,p: 53% 30% 12%  5%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 31% 20% 41%  2%  1%  1%  1%  1%  1%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 28% 17%  2%  3%  3%  3%  2%  1%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mi8c dc,h,v,p: 40% 25% 31%  4%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mref P L0: 63.7%  8.8% 21.4%  6.2%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mref B L0: 82.7% 14.5%  2.9%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mref B L1: 93.3%  6.7%\n",
      "\u001b[1;36m[libx264 @ 0x5a909df2bc00] \u001b[0mkb/s:1341.56\n",
      "\u001b[1;36m[aac @ 0x5a909df0da80] \u001b[0mQavg: 8499.105\n"
     ]
    }
   ],
   "source": [
    "#@title 2.Create Wav2Lip video (using wav2lip_gan.pth) GAN\n",
    "!python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"mf_still.mp4\" --audio \"output.wav\" --pads 0 20 0 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "WxbzXZvLliiA",
    "outputId": "e18c616c-db0b-4ed0-883f-0d8706481d97"
   },
   "outputs": [],
   "source": [
    "#@title 3.Play result video -  50% scaling\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('results/result_voice.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=\"50%\" height=\"50%\" controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1kt-krsEbz5j",
    "outputId": "08159df5-5e58-4201-a8d8-f9dd212a2c27"
   },
   "outputs": [],
   "source": [
    "#@title 4.Download Result.mp4 to your computer\n",
    "from google.colab import files\n",
    "files.download('/content/Wav2Lip/results/result_voice.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "fT8njpBCJ7gD"
   },
   "outputs": [],
   "source": [
    "#@title 5. Delete old uploaded samples & result files, so you can start over again.\n",
    "%rm /content/sample_data/*\n",
    "%rm /content/Wav2Lip/results/*\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "print(\"\\nDone! now press X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgMkHOFqT2fK"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true
    },
    "id": "2OhT0w2uT4rQ"
   },
   "outputs": [],
   "source": [
    "#@title 1-4. Batch processing - Upload -> process -> download -> play result\n",
    "%cd sample_data/\n",
    "%rm input_audio.wav\n",
    "%rm input_video.mp4\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "%cd ..\n",
    "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\"\n",
    "from google.colab import files\n",
    "files.download('/content/Wav2Lip/results/result_voice.mp4')\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=\"50%\" height=\"50%\" controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9NvwrJ3vRcs"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7zgfrQqbKom"
   },
   "source": [
    "# **Variations to try**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xw0xFtZ2bsx8"
   },
   "outputs": [],
   "source": [
    "#@title 2.Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces.\n",
    "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --resize_factor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "45XW4SZAzIz5"
   },
   "outputs": [],
   "source": [
    "#@title 3.Use more padding to include the chin region (u can manually edit pads dimensions viewing and changing the code)\n",
    "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/input_video.mp4\" --audio \"/content/sample_data/input_audio.wav\" --pads 0 20 0 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true
    },
    "id": "X1Z0zRdZR5BZ"
   },
   "outputs": [],
   "source": [
    "#@title 4.Play result video -  50% scaling\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=\"50%\" height=\"50%\" controls>\n",
    "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "gfXFOpAmR_dh"
   },
   "outputs": [],
   "source": [
    "#@title 5.Download Result.mp4 to your computer\n",
    "from google.colab import files\n",
    "files.download('/content/Wav2Lip/results/result_voice.mp4')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "wav2lip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
